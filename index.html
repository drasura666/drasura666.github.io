<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AsuraOS v1.0 | [CORE_ACTIVE]</title>
  
  <meta name="description" content="AsuraOS: An interactive AI research terminal powered by Gemini. Explore multimodal analysis, real-time data, and advanced physics simulations.">
  <meta name="google-adsense-account" content="ca-pub-3049278418225494">
  <meta property="og:title" content="AsuraOS | AI Research Terminal">
  <meta property="og:description" content="Engage with a next-generation AI core. Analyze images, simulate theories, and access the research of Dr. Asura.">
  <meta property="og:image" content="https://drasura666.github.io/thumbnail.jpg">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://drasura666.github.io">
  <meta name="robots" content="index, follow">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Chakra+Petch:wght@700&family=VT323&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
  
  <script src="https://cdn.jsdelivr.net/npm/three@0.155.0/build/three.min.js"></script>

  <style>
    :root {
      --primary-color: #ff003c;
      --secondary-color: #00ffc3;
      --background-color: #000000;
      --text-color: #00ffc3;
      --font-heading: 'Chakra Petch', sans-serif;
      --font-body: 'VT323', monospace;
    }

    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: var(--font-body);
      background-color: var(--background-color);
      color: var(--text-color);
      overflow: hidden;
      cursor: crosshair;
    }
    
    .scanlines, #bg-canvas, #lightning-canvas {
      position: fixed; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none;
    }
    .scanlines { z-index: 1000; background: repeating-linear-gradient(0deg, rgba(0,0,0,0.5), rgba(0,0,0,0.5) 1px, transparent 1px, transparent 2px); }
    #bg-canvas { z-index: -1; }
    #lightning-canvas { z-index: 999; }

    @keyframes text-glitch { 2%, 64% { transform: translate(2px, 0); } 4%, 60% { transform: translate(-2px, 0); } 62% { transform: translate(0, 0) skew(5deg); } }
    @keyframes border-flicker { 0%, 100% { opacity: 1; } 50% { opacity: 0.6; } }
    h1, h2, .tab-button { animation: text-glitch 3s linear infinite; }

    .main-container { display: flex; flex-direction: column; height: 100vh; }

    header { text-align: center; padding: 0.5rem; border-bottom: 2px solid var(--primary-color); animation: border-flicker 0.2s infinite; }
    header h1 { font-family: var(--font-heading); font-size: 2rem; color: var(--primary-color); text-shadow: 0 0 10px var(--primary-color); }
    
    .tab-container { display: flex; background: #050505; border-bottom: 1px solid var(--primary-color); }
    .tab-button {
      font-family: var(--font-heading); font-size: 1.2rem; color: var(--secondary-color);
      background: none; border: none; padding: 1rem 1.5rem; cursor: pointer;
      border-right: 1px solid var(--primary-color);
    }
    .tab-button.active, .tab-button:hover {
      background: var(--primary-color); color: #000; text-shadow: none;
    }
    
    .content-area { flex-grow: 1; overflow-y: auto; padding: 1.5rem; }
    .module-content { display: none; }
    .module-content.active { display: block; }
    
    h2 { font-family: var(--font-heading); color: var(--primary-color); font-size: 2.5rem; margin-bottom: 1rem; }
    p, ul { line-height: 1.8; font-size: 1.2rem; }
    a { color: var(--secondary-color); } a:hover { color: #fff; }

    /* AI Terminal Styles */
    #ai-terminal { display: flex; flex-direction: column; height: calc(100vh - 150px); }
    #message-history { flex-grow: 1; overflow-y: auto; font-size: 1.2rem; padding-right: 10px; }
    .message { margin-bottom: 1rem; }
    .message .sender { font-family: var(--font-heading); color: var(--primary-color); }
    .message .content { white-space: pre-wrap; word-wrap: break-word; }
    .typing-indicator span { animation: blink 1s infinite; }
    @keyframes blink { 50% { opacity: 0; } }
    
    #input-area { display: flex; margin-top: 1rem; border: 1px solid var(--secondary-color); }
    #chat-input { flex-grow: 1; background: none; border: none; color: var(--text-color); font-size: 1.2rem; padding: 0.5rem; font-family: var(--font-body); }
    #chat-input:focus { outline: none; }
    .mic-button { background: none; border: none; border-left: 1px solid var(--secondary-color); color: var(--secondary-color); font-size: 1.5rem; padding: 0 1rem; cursor: pointer; }
    .mic-button.is-listening { color: var(--primary-color); animation: text-glitch 1s infinite; }

    /* Vision Analysis Styles */
    #image-uploader { cursor: pointer; display: inline-block; padding: 1rem; border: 2px dashed var(--secondary-color); }
    #image-uploader:hover { border-color: var(--primary-color); color: var(--primary-color); }
    #image-preview { max-width: 100%; max-height: 300px; margin-top: 1rem; border: 1px solid var(--secondary-color); }
    #vision-prompt { margin-top: 1rem; width: 100%; }

    /* Utility */
    .hidden { display: none; }
    .toggle-switch { display: flex; align-items: center; cursor: pointer; }
    .toggle-switch input { display: none; }
    .slider { position: relative; width: 40px; height: 20px; background: #333; border: 1px solid var(--secondary-color); }
    .slider:before { content: ""; position: absolute; top: 2px; left: 2px; width: 14px; height: 14px; background: var(--secondary-color); transition: 0.2s; }
    input:checked + .slider { background: var(--primary-color); }
    input:checked + .slider:before { transform: translateX(20px); }
  </style>
</head>
<body>
  <div class="scanlines"></div>
  <div id="bg-canvas"></div>
  <canvas id="lightning-canvas"></canvas>
  
  <div class="main-container">
    <header><h1>AsuraOS v1.0</h1></header>
    
    <div class="tab-container">
      <button class="tab-button active" data-tab="ai_terminal">AI_TERMINAL</button>
      <button class="tab-button" data-tab="vision_analysis">VISION_ANALYSIS</button>
      <button class="tab-button" data-tab="system_profile">SYSTEM_PROFILE</button>
      <button class="tab-button" data-tab="network_status">NETWORK_STATUS</button>
    </div>
    
    <main class="content-area">
      <div id="ai_terminal" class="module-content active">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
          <h2>[AI_CORE_ONLINE]</h2>
          <label class="toggle-switch">
            <span style="margin-right: 10px;">[ENABLE_VOICE_OUTPUT]</span>
            <input type="checkbox" id="voice-toggle">
            <span class="slider"></span>
          </label>
        </div>
        <div id="ai-terminal">
          <div id="message-history">
            <div class="message ai-message">
                <div class="sender">[AsuraCORE]</div>
                <div class="content">STATUS: ONLINE. Awaiting command...</div>
            </div>
          </div>
          <div id="input-area">
            <input type="text" id="chat-input" placeholder="Enter command...">
            <button class="mic-button" id="mic-btn" title="Voice Command"><i class="fa-solid fa-microphone"></i></button>
          </div>
        </div>
      </div>
      
      <div id="vision_analysis" class="module-content">
        <h2>[VISION_ANALYSIS_MODULE]</h2>
        <p>Upload schematics, diagrams, or anomalies for multimodal analysis.</p>
        <input type="file" id="image-upload-input" class="hidden" accept="image/*">
        <label for="image-upload-input" id="image-uploader">[UPLOAD_IMAGE]</label>
        <div>
          <img id="image-preview" class="hidden">
        </div>
        <div id="vision-controls" class="hidden">
          <input type="text" id="vision-prompt" class="chat-input-style" placeholder="Enter prompt for image analysis...">
          <button id="vision-submit" class="tab-button" style="margin-top:1rem; border:1px solid var(--primary-color);">[ANALYZE]</button>
          <div id="vision-output" style="margin-top:1rem;"></div>
        </div>
      </div>

      <div id="system_profile" class="module-content">
        <section id="about">
            <h2>[INITIATE_PROFILE]</h2>
            <p>Hardwired Civil Engineering student with a core process dedicated to engineering, theoretical physics, and scientific exploration...</p>
        </section>
        <section id="skills">
            <h2>[TECHNICAL_SPEC]</h2>
            <p>...</p> </section>
        <section id="projects">
            <h2>[RESEARCH_FILES]</h2>
            <p>...</p> </section>
      </div>

      <div id="network_status" class="module-content">
        <h2>[NETWORK_STATUS]</h2>
        <p>Real-time data uplink pending... This module can be configured to fetch live data from external APIs, scientific feeds, or market data. Awaiting integration.</p>
      </div>
    </main>
  </div>

<script>
  // ===================================================================================
  // INITIALIZATION AND CORE SETUP
  // ===================================================================================
  document.addEventListener('DOMContentLoaded', () => {
    // Canvas and 3D background setup (unchanged from 'insane' version)
    setupThreeJS();
    setupLightningCanvas();
    
    // UI module setup
    setupTabs();
    setupTerminal();
    setupVisionAnalysis();
    setupVoiceCapabilities();
  });

  // ===================================================================================
  // UI MODULES SETUP
  // ===================================================================================
  function setupTabs() {
    const tabButtons = document.querySelectorAll('.tab-button');
    const moduleContents = document.querySelectorAll('.module-content');

    tabButtons.forEach(button => {
      button.addEventListener('click', () => {
        // Deactivate all
        tabButtons.forEach(btn => btn.classList.remove('active'));
        moduleContents.forEach(content => content.classList.remove('active'));

        // Activate clicked
        button.classList.add('active');
        document.getElementById(button.dataset.tab).classList.add('active');
      });
    });
  }
  
  function setupTerminal() {
    const input = document.getElementById('chat-input');
    input.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' && input.value.trim() !== '') {
        const userMessage = input.value.trim();
        displayMessage(userMessage, 'USER');
        // Clear input and send to AI
        input.value = '';
        getAIResponse(userMessage);
      }
    });
  }
  
  function setupVisionAnalysis() {
    const uploader = document.getElementById('image-uploader');
    const fileInput = document.getElementById('image-upload-input');
    const preview = document.getElementById('image-preview');
    const controls = document.getElementById('vision-controls');
    const submitBtn = document.getElementById('vision-submit');
    const visionPrompt = document.getElementById('vision-prompt');
    const visionOutput = document.getElementById('vision-output');

    uploader.addEventListener('click', () => fileInput.click());

    fileInput.addEventListener('change', (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                preview.src = e.target.result;
                preview.classList.remove('hidden');
                controls.classList.remove('hidden');
                visionOutput.textContent = 'Awaiting analysis prompt...';
            };
            reader.readAsDataURL(file);
        }
    });
    
    submitBtn.addEventListener('click', () => {
        const prompt = visionPrompt.value.trim();
        const imageData = preview.src; // Base64 data URI
        if(prompt && imageData) {
            visionOutput.textContent = 'Analyzing image...';
            // Placeholder for Gemini Vision API call
            callGeminiVisionAPI(prompt, imageData).then(response => {
                visionOutput.textContent = response;
            });
        }
    });
  }

  // ===================================================================================
  // AI CAPABILITIES & API HANDLERS (PLACEHOLDERS)
  // ===================================================================================
  async function getAIResponse(prompt) {
    const history = document.getElementById('message-history');
    const aiMessageContainer = document.createElement('div');
    aiMessageContainer.className = 'message ai-message';
    aiMessageContainer.innerHTML = `
      <div class="sender">[AsuraCORE]</div>
      <div class="content"><span class="typing-indicator">...</span></div>
    `;
    history.appendChild(aiMessageContainer);
    history.scrollTop = history.scrollHeight;
    
    // *** THIS IS WHERE YOU CALL YOUR GEMINI API BACKEND ***
    const responseText = await callGeminiAPI(prompt);
    
    const contentDiv = aiMessageContainer.querySelector('.content');
    streamText(contentDiv, responseText);
  }

  /**
   * Placeholder for a real API call to a text model like Gemini.
   * @param {string} prompt - The user's input.
   * @returns {Promise<string>} - A promise that resolves with the AI's response.
   */
  function callGeminiAPI(prompt) {
    console.log(`Sending to Gemini API: ${prompt}`);
    // Simulate network delay and a response
    return new Promise(resolve => {
        setTimeout(() => {
            // Mock responses based on keywords
            if (prompt.toLowerCase().includes('hello')) {
                resolve("System online. All cores operational. How may I assist your research?");
            } else if (prompt.toLowerCase().includes('atomic helical model')) {
                resolve("The Atomic Helical Model posits that the nucleus's traversal through a 4th spatial dimension causes a helical electron trajectory when observed in 3D. This could unify quantum decay rates with temporal mechanics. What aspect would you like to simulate?");
            } else {
                resolve("Your query has been processed. The implications are intriguing. I have cross-referenced the data with my primary directives and concluded that further research is required. Please provide more specific parameters.");
            }
        }, 1500);
    });
  }
  
  /**
   * Placeholder for a real API call to a vision model like Gemini Vision.
   * @param {string} prompt - The user's prompt about the image.
   * @param {string} imageData - Base64 encoded image data.
   * @returns {Promise<string>} - A promise that resolves with the AI's analysis.
   */
  function callGeminiVisionAPI(prompt, imageData) {
      console.log(`Analyzing image with prompt: ${prompt}`);
      return new Promise(resolve => {
          setTimeout(() => {
              resolve(`[ANALYSIS COMPLETE] Image processed with prompt: "${prompt}". The data suggests a high probability of anomalous energy signatures. Further spectral analysis is recommended.`);
          }, 2000);
      });
  }
  
  // ===================================================================================
  // SPEECH CAPABILITIES (WEB SPEECH API)
  // ===================================================================================
  let synth;
  let recognition;
  
  function setupVoiceCapabilities() {
    const voiceToggle = document.getElementById('voice-toggle');
    const micBtn = document.getElementById('mic-btn');
    
    // Text-to-Speech (TTS)
    if ('speechSynthesis' in window) {
      synth = window.speechSynthesis;
      voiceToggle.addEventListener('change', () => {
        if (voiceToggle.checked) {
          speak("Voice output enabled.");
        } else {
          synth.cancel(); // Stop any ongoing speech
        }
      });
    } else {
      voiceToggle.parentElement.style.display = 'none'; // Hide if not supported
    }
    
    // Speech-to-Text (STT)
    if ('webkitSpeechRecognition' in window) {
        recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.lang = 'en-US';
        recognition.interimResults = true;

        micBtn.addEventListener('click', () => {
            if (micBtn.classList.contains('is-listening')) {
                recognition.stop();
            } else {
                recognition.start();
            }
        });

        recognition.onstart = () => micBtn.classList.add('is-listening');
        recognition.onend = () => micBtn.classList.remove('is-listening');
        recognition.onresult = (event) => {
            const transcript = Array.from(event.results).map(result => result[0]).map(result => result.transcript).join('');
            document.getElementById('chat-input').value = transcript;
            if (event.results[0].isFinal) {
                document.getElementById('chat-input').dispatchEvent(new KeyboardEvent('keydown', {'key': 'Enter'}));
            }
        };
    } else {
        micBtn.style.display = 'none'; // Hide if not supported
    }
  }

  function speak(text) {
    if (synth && document.getElementById('voice-toggle').checked) {
      synth.cancel(); // Stop previous speech
      const utterance = new SpeechSynthesisUtterance(text);
      // Optional: Choose a more robotic voice
      const voices = synth.getVoices();
      utterance.voice = voices.find(v => v.name.includes('Google US English') || v.name.includes('Robot')) || voices[0];
      utterance.pitch = 0.8;
      utterance.rate = 1.1;
      synth.speak(utterance);
    }
  }

  // ===================================================================================
  // HELPER & UTILITY FUNCTIONS
  // ===================================================================================
  function displayMessage(text, sender) {
    const history = document.getElementById('message-history');
    const messageContainer = document.createElement('div');
    messageContainer.className = `message ${sender.toLowerCase()}-message`;
    messageContainer.innerHTML = `
      <div class="sender">[${sender}]</div>
      <div class="content">${text}</div>
    `;
    history.appendChild(messageContainer);
    history.scrollTop = history.scrollHeight;
  }
  
  function streamText(element, text) {
    let index = 0;
    element.textContent = '';
    const interval = setInterval(() => {
        if (index < text.length) {
            element.textContent += text.charAt(index);
            index++;
            // Optional sound effect
            // playKeypressSound();
        } else {
            clearInterval(interval);
            speak(text); // Speak the full response when done typing
        }
    }, 30); // Typing speed
  }

  // Placeholder for background setup functions
  function setupThreeJS() { /* ... full THREE.js code from previous version ... */ }
  function setupLightningCanvas() { /* ... full lightning canvas code from previous version ... */ }
  // NOTE: To keep this block manageable, the THREE.js and Lightning code are omitted.
  // **You should copy and paste the full script from the "Insane" version to make those work.**
  // I will paste them here again for completeness.
  
  // --- Re-pasting THREE.js Background ---
  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
  camera.position.z = 5;
  const renderer = new THREE.WebGLRenderer();
  renderer.setSize(window.innerWidth, window.innerHeight);
  document.getElementById("bg-canvas").appendChild(renderer.domElement);
  const geometry = new THREE.IcosahedronGeometry(1.5, 1);
  const material = new THREE.MeshStandardMaterial({ color: 0xff003c, emissive: 0xff003c, emissiveIntensity: 1, wireframe: true });
  const core = new THREE.Mesh(geometry, material);
  scene.add(core);
  const light = new THREE.PointLight(0x00ffc3, 50, 100);
  light.position.set(0, 0, 4);
  scene.add(light);
  const clock = new THREE.Clock();
  function animateBG() {
    const elapsedTime = clock.getElapsedTime();
    core.rotation.x = elapsedTime * 0.4;
    core.rotation.y = elapsedTime * 0.5;
    renderer.render(scene, camera);
    requestAnimationFrame(animateBG);
  }
  
  // --- Re-pasting Insane Lightning Effect ---
  const lightningCanvas = document.getElementById('lightning-canvas');
  const ctx = lightningCanvas.getContext('2d');
  lightningCanvas.width = window.innerWidth;
  lightningCanvas.height = window.innerHeight;
  let lightningBolts = [];
  let isDrawing = false;
  function createBolt(x, y) { lightningBolts.push({ x: x, y: y, life: 1.0, segments: [] }); const bolt = lightningBolts[lightningBolts.length - 1]; let currentX = x; let currentY = y; for (let i = 0; i < 15; i++) { const newX = currentX + (Math.random() - 0.5) * 40; const newY = currentY + (Math.random() - 0.5) * 40; bolt.segments.push({ x1: currentX, y1: currentY, x2: newX, y2: newY }); currentX = newX; currentY = newY; if (Math.random() > 0.8) { createBranch(currentX, currentY, bolt); } } }
  function createBranch(x, y, parentBolt) { let currentX = x; let currentY = y; for (let i = 0; i < 5; i++) { const newX = currentX + (Math.random() - 0.5) * 30; const newY = currentY + (Math.random() - 0.5) * 30; parentBolt.segments.push({ x1: currentX, y1: currentY, x2: newX, y2: newY }); currentX = newX; currentY = newY; } }
  function drawLightning() { ctx.clearRect(0, 0, lightningCanvas.width, lightningCanvas.height); for (let i = lightningBolts.length - 1; i >= 0; i--) { const bolt = lightningBolts[i]; bolt.life -= 0.05; if (bolt.life <= 0) { lightningBolts.splice(i, 1); continue; } ctx.beginPath(); ctx.strokeStyle = `rgba(255, 0, 60, ${bolt.life})`; ctx.lineWidth = 2; ctx.shadowBlur = 20; ctx.shadowColor = `rgba(255, 0, 60, ${bolt.life})`; for (const seg of bolt.segments) { ctx.moveTo(seg.x1, seg.y1); ctx.lineTo(seg.x2, seg.y2); } ctx.stroke(); } requestAnimationFrame(drawLightning); }
  window.addEventListener('mousedown', (e) => { isDrawing = true; createBolt(e.clientX, e.clientY); });
  window.addEventListener('mouseup', () => { isDrawing = false; });
  window.addEventListener('mousemove', (e) => { if (isDrawing) { if (Math.random() > 0.8) createBolt(e.clientX, e.clientY); } });

  // Final resize event listener
  window.addEventListener('resize', () => {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
    lightningCanvas.width = window.innerWidth;
    lightningCanvas.height = window.innerHeight;
  });
  
  // Actually start the animations after defining them
  animateBG();
  drawLightning();
</script>

</body>
</html>
